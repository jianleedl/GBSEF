## Granular-ball Sample Enhancement-based defense Framework
This is a defense architecture based on Pytorch implementation against text synonym substitution attacks
### Environment
Our experiments environment is as below
1. Ubuntu 18.0.4
2. Python 3.7.4
3. PyTorch 1.13.1
4. pyspellchecker 0.7.2
5. numpy 1.21.6
6. nltk 3.8.1
7. scikit-learn 1.0.2

### Download dataset and GloVe vectors
You need to download [IMDB](https://s3.amazonaws.com/fast-ai-nlp/imdb.tgz), [AG's News](https://s3.amazonaws.com/fast-ai-nlp/ag_news_csv.tgz) and [Yahoo! Answers](https://s3.amazonaws.com/fast-ai-nlp/yahoo_answers_csv.tgz) dataset and place them in ``./dataset/``.  
Download pretrained GloVe vectors ([.6B.100d](https://nlp.stanford.edu/projects/glove/)) and place it in ``./static/``

### Experiments
1. Generate standard datasets and sample 1k data from origin test dataset for attackers to generate adversarial examples.
```
python tools.py --dataset IMDB --num 1000
```
You will get standard datasets in path ``./dataset/IMDB/`` and ``clean1k.txt`` in path ``./static/IMDB/``

2. Generate the original set of synonyms
```
python synonym.py --dataset IMDB
```
You will get ``synonymous.csv`` in path ``./static/IMDB/``

3. train by GSEF
```
python train.py --dataset IMDB --model LSTM --enhanced yes --adv no --load_model no --epoch 100 --batch 64 --lr 3e-3 
```
The best model will be saved in ``./models/IMDB/LSTM_enhanced_acc_time.pt``. And remember to correct the model load path in ``config.py``.
```
config_model_load_path = {
    'IMDB': {
        'LSTM_enhanced': 'LSTM_enhanced_acc_time.pt',
    },
}
```
4. Attack
Attackers supported is PWWS, TEXTFOOL, GA.  
Make sure the ``config_dataset`` in ``config.py`` is as same as the ``dataset`` in below commands.
```
python fool.py --dataset IMDB --attack PWWS --model LSTM_enhanced
```
The detailed attack results ``$time.csv`` and generated adversarial examples ``$time.txt`` are in ``static/DatasetName/foolresult/AttackerName/TargetModelName/``

5. Evaluate results
The evaluation will show the target model's performance on origin test dataset, clean data and adversarial data.  
```
python evaluate.py --dataset IMDB --models LSTM_enhanced --adv_paths adv_data.txt --save_path ./result.csv
```
``adv_data.txt`` is adversarial examples generated by the attacker.
